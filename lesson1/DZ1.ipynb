{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Урок 1. Алгоритм линейной регрессии. Градиентный спуск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ak8b3KV45kVW"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "              [1, 1, 2, 5, 3, 0, 5, 10, 1, 2]])\n",
    "y = [45, 55, 50, 55, 60, 35, 75, 80, 50, 60]\n",
    "\n",
    "def calc_mse(y, y_pred):\n",
    "    err = np.mean((y - y_pred)**2) # <=> 1/n * np.sum((y_pred - y)**2)\n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Д/З"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "huXrhXQsZTMt"
   },
   "source": [
    "1. Подберите скорость обучения (alpha) и количество итераций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "IDB22MQKMYaJ",
    "outputId": "4c03219e-a57c-4583-f439-6699fd0619bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of objects = 10        \n",
      "Learning rate = 0.0555        \n",
      "Initial weights = [1.  0.5] \n",
      "\n",
      "Iteration #122: W_new = [44.99436978  3.83950659], MSE = 43.98\n",
      "Iteration #123: W_new = [44.99293904  3.81123251], MSE = 43.97\n"
     ]
    }
   ],
   "source": [
    "n = X.shape[1]\n",
    "alpha = 5.55e-2\n",
    "W = np.array([1, 0.5])\n",
    "print(f'Number of objects = {n} \\\n",
    "       \\nLearning rate = {alpha} \\\n",
    "       \\nInitial weights = {W} \\n')\n",
    "\n",
    "for i in range(124):\n",
    "    y_pred = np.dot(W, X)\n",
    "    err = calc_mse(y, y_pred)\n",
    "    for k in range(W.shape[0]):\n",
    "        W[k] -= alpha * (1/n * 2 * np.sum(X[k] * (y_pred - y)))\n",
    "    if i > 121:\n",
    "        print(f'Iteration #{i}: W_new = {W}, MSE = {round(err,2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Qu1o4JhZYwI"
   },
   "source": [
    "*2. В этом коде мы избавляемся от итераций по весам, но тут есть ошибка, исправьте ее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of objects = 10        \n",
      "Learning rate = 0.01        \n",
      "Initial weights = [1.  0.5] \n",
      "\n",
      "Iteration #0: W_new = [2.08 4.27], MSE = 3047.75\n",
      "Iteration #10: W_new = [ 7.0011236 10.6169007], MSE = 738.65\n",
      "Iteration #20: W_new = [10.3486292  10.10603105], MSE = 622.03\n",
      "Iteration #30: W_new = [13.38789582  9.55618391], MSE = 525.24\n",
      "Iteration #40: W_new = [16.16088505  9.05336203], MSE = 444.66\n",
      "Iteration #50: W_new = [18.69110735  8.59454545], MSE = 377.58\n",
      "Iteration #60: W_new = [20.99981865  8.17589626], MSE = 321.72\n",
      "Iteration #70: W_new = [23.10641138  7.79389815], MSE = 275.22\n",
      "Iteration #80: W_new = [25.02858024  7.44534246], MSE = 236.5\n",
      "Iteration #90: W_new = [26.78247081  7.12730145], MSE = 204.27\n"
     ]
    }
   ],
   "source": [
    "n = X.shape[1]\n",
    "alpha = 1e-2\n",
    "W = np.array([1, 0.5])\n",
    "print(f'Number of objects = {n} \\\n",
    "       \\nLearning rate = {alpha} \\\n",
    "       \\nInitial weights = {W} \\n')\n",
    "\n",
    "for i in range(100):\n",
    "    y_pred = np.dot(W, X)\n",
    "    err = calc_mse(y, y_pred)\n",
    "    W -= alpha * (1/n * 2 * np.sum(X * (y_pred - y), axis=1)) #не было указанно по какой оси производить суммирование\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(f'Iteration #{i}: W_new = {W}, MSE = {round(err,2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание *3: вместо того, чтобы задавать количество итераций, задайте условие остановки алгоритма - когда ошибка за итерацию начинает изменяться ниже определенного порога (упрощенный аналог параметра tol в линейной регрессии в sklearn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kGLyytFgHdco"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of objects = 10        \n",
      "Learning rate = 0.0555        \n",
      "Initial weights = [1.  0.5] \n",
      "\n",
      "Iteration #99: W_new = [44.79351523  3.80468519], MSE = 44.05\n"
     ]
    }
   ],
   "source": [
    "n = X.shape[1]\n",
    "alpha = 5.55e-2\n",
    "W = np.array([1, 0.5])\n",
    "print(f'Number of objects = {n} \\\n",
    "       \\nLearning rate = {alpha} \\\n",
    "       \\nInitial weights = {W} \\n')\n",
    "\n",
    "tol_my = 0.01\n",
    "err_old = 0\n",
    "for i in range(1, 150):\n",
    "    y_pred = np.dot(W, X)\n",
    "    err = calc_mse(y, y_pred)\n",
    "    delta_error = abs(err_old - err)\n",
    "    if delta_error <= tol_my:\n",
    "        print(f'Iteration #{i}: W_new = {W}, MSE = {round(err,2)}')\n",
    "        break;\n",
    "\n",
    "    W -= (alpha) * (1/n * 2 * np.sum(X * (y_pred - y), axis=1))\n",
    "    err_old = err"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lesson1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
